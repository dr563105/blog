{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d6f2b3",
   "metadata": {},
   "source": [
    "# \"Getting started with S3 using boto3\"\n",
    "> \"An introduction to S3 with boto3 AWS python SDK\"\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- permalink: /s3_with_boto3/\n",
    "- categories: [aws s3, s3, boto3, buckets]\n",
    "- image: images/s3-logo.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfceee48",
   "metadata": {},
   "source": [
    "**Boto3** is an AWS python SDK that allows access to AWS services like EC2 and S3. It provides a python object-oriented API and as well as low-level access to AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e72e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#collapse-output\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697bc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, botocore\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba8d383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Player Data.xlsx',\n",
       " 'data/30-days-create-folds.ipynb',\n",
       " 'data/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv',\n",
       " 'data/star_pattern_turtlesim.png']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('data/*') #to upload multiple files\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ce976",
   "metadata": {},
   "source": [
    "## Create a session and client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c963f4b",
   "metadata": {},
   "source": [
    "Boto3's region defaults to N-Virginia. To create buckets in another region, region name has to be explicitly mentioned using session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4c5ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name='us-east-2')\n",
    "s3client = session.client('s3')\n",
    "s3resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4512b92",
   "metadata": {},
   "source": [
    "S3 buckets have to follow bucket naming [rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efd1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_names = ['my-s3bucket1-usohio-region', 'my-s3bucket2-usohio-region']\n",
    "s3location = {'LocationConstraint': 'us-east-2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e10c42",
   "metadata": {},
   "source": [
    "## Check if bucket exists in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de39780",
   "metadata": {},
   "source": [
    "Checking for something before creation is one of the important tasks to avoid unnecessary errors. Here we check if the buckets already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1d3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bucket(bucket):\n",
    "    \"\"\"\n",
    "    Checks if a bucket is present in S3\n",
    "    args:\n",
    "    bucket: takes bucket name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3client.head_bucket(Bucket=bucket)\n",
    "        print('Bucket exists')\n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        # If a client error is thrown, then check that it was a 404 error.\n",
    "        # If it was a 404 error, then the bucket does not exist.\n",
    "        error_code = int(e.response['Error']['Code'])\n",
    "        if error_code == 403:\n",
    "            print(\"Private Bucket. Forbidden Access!\")\n",
    "            return True\n",
    "        elif error_code == 404:\n",
    "            print(\"Bucket Does Not Exist!\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb798300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Does Not Exist!\n",
      "False\n",
      "Bucket Does Not Exist!\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for bucket in bucket_names: \n",
    "    print(check_bucket(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9d19d",
   "metadata": {},
   "source": [
    "## Create a bucket in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979c686",
   "metadata": {},
   "source": [
    "If the buckets don't exist, we create them. We need to supply bucket name, a dictionary specifying in which region the bucket has to be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2525df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket Does Not Exist!\n",
      "Creating a bucket..\n",
      "Bucket Does Not Exist!\n",
      "Creating a bucket..\n"
     ]
    }
   ],
   "source": [
    "for bucket_name in bucket_names: \n",
    "    if not(check_bucket(bucket_name)):\n",
    "        print('Creating a bucket..')\n",
    "        s3client.create_bucket(Bucket = bucket_name, CreateBucketConfiguration=s3location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9fce74",
   "metadata": {},
   "source": [
    "## Bucket Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9036c8a3",
   "metadata": {},
   "source": [
    "Bucket versioning initial state is not set by default. The response from  when not initialised doesn't carry status information rather status dict is absent. Status expects two return states: **enabled**, **suspended**. On first creation, the status is in disabled, an unknown state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764a973",
   "metadata": {},
   "source": [
    "So in order to make it appear in the REST response, bucket must be enabled by calling the `BucketVersioning()` boto3 resource function. If we then check the status, it will be present in the REST response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e76150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buckets_versioning_client(bucketname):\n",
    "    \"\"\"\n",
    "    Checks if bucket versioning is enabled/suspended or initialised\n",
    "    Args:\n",
    "    bucketname: bucket name to check versioning\n",
    "    Returns: response status - enabled or suspended\n",
    "    \"\"\"\n",
    "    response = s3client.get_bucket_versioning(Bucket = bucketname)\n",
    "    if 'Status' in response and (response['Status'] == 'Enabled' or response['Status'] == 'Suspended'):\n",
    "        print(f'Bucket {bucketname} status: {response[\"Status\"]}')\n",
    "        return response['Status']\n",
    "    else:\n",
    "        print(f'Bucket versioning not initialised for bucket: {bucketname}. Enabling...')\n",
    "        s3resource.BucketVersioning(bucket_name=bucketname).enable()\n",
    "        enable_response = s3resource.BucketVersioning(bucket_name=bucket_name).status\n",
    "        return enable_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a0c70e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket versioning not initialised for bucket: my-s3bucket1-usohio-region. Enabling...\n",
      "Versioning status: Enabled\n",
      "Bucket versioning not initialised for bucket: my-s3bucket2-usohio-region. Enabling...\n",
      "Versioning status: Enabled\n"
     ]
    }
   ],
   "source": [
    "for bucket_name in bucket_names: \n",
    "    version_status = get_buckets_versioning_client(bucket_name)\n",
    "    print(f'Versioning status: {version_status}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05edff83",
   "metadata": {},
   "source": [
    "## To suspend bucket versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437a0faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket my-s3bucket1-usohio-region status: Enabled\n",
      "Versioning status: Enabled\n",
      "Disabling again..\n",
      "Bucket my-s3bucket2-usohio-region status: Enabled\n",
      "Versioning status: Enabled\n",
      "Disabling again..\n"
     ]
    }
   ],
   "source": [
    "for bucket_name in bucket_names:\n",
    "    version_status = get_buckets_versioning_client(bucket_name)\n",
    "    print(f'Versioning status: {version_status}')\n",
    "    if version_status == 'Enabled':\n",
    "        print('Disabling again..')\n",
    "        s3resource.BucketVersioning(bucket_name=bucket_name).suspend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f8309",
   "metadata": {},
   "source": [
    "## To enable bucket versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9675b45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket my-s3bucket1-usohio-region status: Suspended\n",
      "Versioning status: Suspended\n",
      "Enabling again..\n",
      "Bucket my-s3bucket2-usohio-region status: Suspended\n",
      "Versioning status: Suspended\n",
      "Enabling again..\n"
     ]
    }
   ],
   "source": [
    "for bucket_name in bucket_names:\n",
    "    version_status = get_buckets_versioning_client(bucket_name)\n",
    "    print(f'Versioning status: {version_status}')\n",
    "    if version_status == 'Suspended':\n",
    "        print('Enabling again..')\n",
    "        s3resource.BucketVersioning(bucket_name=bucket_name).enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10863dbb",
   "metadata": {},
   "source": [
    "## Get bucket list from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9fa8d",
   "metadata": {},
   "source": [
    "We can list the buckets in S3 using `list_buckets()` client function. It return a dict. We can iterate through `Buckets` key to find the names of the buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40cb9cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-s3bucket1-usohio-region\n",
      "my-s3bucket2-usohio-region\n"
     ]
    }
   ],
   "source": [
    "buckets_list = s3client.list_buckets()\n",
    "for bucket in buckets_list['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468cdf07",
   "metadata": {},
   "source": [
    "## Upload files to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fc887",
   "metadata": {},
   "source": [
    "Boto3 allows file upload to S3. The `upload_file` client function requires three mandatory arguments - \n",
    "\n",
    "    1. filename of the file to be uploaded\n",
    "    2. bucket_name, Into which bucket the file would be uploaded\n",
    "    3. key, name of the file in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845b1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_files_to_s3(filename, bucket_name, key=None, ExtraArgs=None):\n",
    "    \"\"\"\n",
    "    Uploads file to S3 bucket\n",
    "    Args:\n",
    "    filename: takes local filename to be uploaded\n",
    "    bucker_name: name of the bucket into which the file is uploaded\n",
    "    key: name of the file in the bucket. Default:None\n",
    "    ExtraArgs: other arguments. Default:None\n",
    "    \"\"\"\n",
    "    if key is None:\n",
    "        key = filename\n",
    "    \n",
    "    try:\n",
    "        s3client.upload_file(filename,bucket_name,key)\n",
    "        print(f'uploaded file:{filename}')\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3266534",
   "metadata": {},
   "source": [
    "We can make use of `glob` module to upload multiple files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af232138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['data/30-days-create-folds.ipynb',\n",
       "  'data/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv'],\n",
       " ['data/Player Data.xlsx', 'data/star_pattern_turtlesim.png'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket1_files = [files[1],files[2]]\n",
    "bucket2_files = [files[0],files[3]]\n",
    "bucket1_files, bucket2_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67dd3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded file:data/30-days-create-folds.ipynb\n",
      "uploaded file:data/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv\n"
     ]
    }
   ],
   "source": [
    "for file in bucket1_files:\n",
    "    upload_files_to_s3(file,bucket_name=bucket_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1b84af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded file:data/Player Data.xlsx\n",
      "uploaded file:data/star_pattern_turtlesim.png\n"
     ]
    }
   ],
   "source": [
    "for file in bucket2_files:\n",
    "    upload_files_to_s3(file,bucket_name=bucket_names[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9874e6",
   "metadata": {},
   "source": [
    "## Get files list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64eda5c",
   "metadata": {},
   "source": [
    "Getting the files list from each bucket done using `list_objects` client function. It returns dict and we can iterate through `Contents` key to retrieve the filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3cb458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing object inside bucket:my-s3bucket1-usohio-region\n",
      "data/30-days-create-folds.ipynb\n",
      "data/ARK_GENOMIC_REVOLUTION_ETF_ARKG_HOLDINGS.csv\n",
      "\n",
      "Listing object inside bucket:my-s3bucket2-usohio-region\n",
      "data/Player Data.xlsx\n",
      "data/star_pattern_turtlesim.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bucket in bucket_names:\n",
    "    print(f'Listing object inside bucket:{bucket}')\n",
    "    list_obj_response = s3client.list_objects(Bucket=bucket)\n",
    "    for obj in list_obj_response['Contents']:\n",
    "        print(obj['Key'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2bae9",
   "metadata": {},
   "source": [
    "## Download files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42021036",
   "metadata": {},
   "source": [
    "Downloading a file is very similar to uploading one. We need specify bucket name, name of the file to be downloaded, and the destination filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4be262e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files from bucket:my-s3bucket2-usohio-region\n"
     ]
    }
   ],
   "source": [
    "print(f'Downloading files from bucket:{bucket_names[1]}')\n",
    "s3client.download_file(Bucket=bucket_names[1],Key='data/star_pattern_turtlesim.png',Filename='downloaded_turtlesim.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efff116",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51850155",
   "metadata": {},
   "source": [
    "This blog post shows how to use the boto3 python SDK to manage S3 aws service. With the help of documentation, we can implement require functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ccda9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('finance')",
   "language": "python",
   "name": "python3102jvsc74a57bd0c9e35cb7ef526b39c9bff46148c4ed78e0d356f49562370d9714bb2aa4ea08bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
